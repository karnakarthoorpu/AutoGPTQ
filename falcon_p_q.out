Requirement already satisfied: flash-attn in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (2.5.8)
Requirement already satisfied: torch in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from flash-attn) (2.3.0)
Requirement already satisfied: einops in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from flash-attn) (0.8.0)
Requirement already satisfied: packaging in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from flash-attn) (24.0)
Requirement already satisfied: ninja in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from flash-attn) (1.11.1.1)
Requirement already satisfied: filelock in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (3.14.0)
Requirement already satisfied: typing-extensions>=4.8.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (4.11.0)
Requirement already satisfied: sympy in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (1.12)
Requirement already satisfied: networkx in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (3.3)
Requirement already satisfied: jinja2 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (3.1.4)
Requirement already satisfied: fsspec in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (2024.3.1)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (2.20.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)
Requirement already satisfied: triton==2.3.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch->flash-attn) (2.3.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.4.127)
Requirement already satisfied: MarkupSafe>=2.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.5)
Requirement already satisfied: mpmath>=0.19 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)
Obtaining file:///lustre1/tier2/users/karnakar.reddy/projects_2024/AutoGPTQ
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: accelerate>=0.26.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from auto_gptq==0.8.0.dev0+cu121) (0.30.1)
Requirement already satisfied: datasets in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from auto_gptq==0.8.0.dev0+cu121) (2.19.1)
Requirement already satisfied: sentencepiece in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from auto_gptq==0.8.0.dev0+cu121) (0.2.0)
Requirement already satisfied: numpy in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from auto_gptq==0.8.0.dev0+cu121) (1.26.4)
Requirement already satisfied: rouge in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from auto_gptq==0.8.0.dev0+cu121) (1.0.1)
Requirement already satisfied: gekko in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from auto_gptq==0.8.0.dev0+cu121) (1.1.1)
Requirement already satisfied: torch>=1.13.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from auto_gptq==0.8.0.dev0+cu121) (2.3.0)
Requirement already satisfied: safetensors in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from auto_gptq==0.8.0.dev0+cu121) (0.4.3)
Requirement already satisfied: transformers>=4.31.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from auto_gptq==0.8.0.dev0+cu121) (4.41.0.dev0)
Requirement already satisfied: peft>=0.5.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from auto_gptq==0.8.0.dev0+cu121) (0.11.1)
Requirement already satisfied: tqdm in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from auto_gptq==0.8.0.dev0+cu121) (4.66.4)
Requirement already satisfied: packaging>=20.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from accelerate>=0.26.0->auto_gptq==0.8.0.dev0+cu121) (24.0)
Requirement already satisfied: psutil in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from accelerate>=0.26.0->auto_gptq==0.8.0.dev0+cu121) (5.9.8)
Requirement already satisfied: pyyaml in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from accelerate>=0.26.0->auto_gptq==0.8.0.dev0+cu121) (6.0.1)
Requirement already satisfied: huggingface-hub in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from accelerate>=0.26.0->auto_gptq==0.8.0.dev0+cu121) (0.23.0)
Requirement already satisfied: filelock in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (3.14.0)
Requirement already satisfied: typing-extensions>=4.8.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (4.11.0)
Requirement already satisfied: sympy in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (1.12)
Requirement already satisfied: networkx in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (3.3)
Requirement already satisfied: jinja2 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (3.1.4)
Requirement already satisfied: fsspec in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (2024.3.1)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (2.20.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (12.1.105)
Requirement already satisfied: triton==2.3.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (2.3.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (12.4.127)
Requirement already satisfied: regex!=2019.12.17 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from transformers>=4.31.0->auto_gptq==0.8.0.dev0+cu121) (2024.5.10)
Requirement already satisfied: requests in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from transformers>=4.31.0->auto_gptq==0.8.0.dev0+cu121) (2.31.0)
Requirement already satisfied: tokenizers<0.20,>=0.19 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from transformers>=4.31.0->auto_gptq==0.8.0.dev0+cu121) (0.19.1)
Requirement already satisfied: pyarrow>=12.0.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from datasets->auto_gptq==0.8.0.dev0+cu121) (16.1.0)
Requirement already satisfied: pyarrow-hotfix in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from datasets->auto_gptq==0.8.0.dev0+cu121) (0.6)
Requirement already satisfied: dill<0.3.9,>=0.3.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from datasets->auto_gptq==0.8.0.dev0+cu121) (0.3.8)
Requirement already satisfied: pandas in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from datasets->auto_gptq==0.8.0.dev0+cu121) (2.2.2)
Requirement already satisfied: xxhash in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from datasets->auto_gptq==0.8.0.dev0+cu121) (3.4.1)
Requirement already satisfied: multiprocess in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from datasets->auto_gptq==0.8.0.dev0+cu121) (0.70.16)
Requirement already satisfied: aiohttp in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from datasets->auto_gptq==0.8.0.dev0+cu121) (3.9.5)
Requirement already satisfied: six in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from rouge->auto_gptq==0.8.0.dev0+cu121) (1.16.0)
Requirement already satisfied: aiosignal>=1.1.2 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.8.0.dev0+cu121) (1.3.1)
Requirement already satisfied: attrs>=17.3.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.8.0.dev0+cu121) (23.2.0)
Requirement already satisfied: frozenlist>=1.1.1 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.8.0.dev0+cu121) (1.4.1)
Requirement already satisfied: multidict<7.0,>=4.5 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.8.0.dev0+cu121) (6.0.5)
Requirement already satisfied: yarl<2.0,>=1.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.8.0.dev0+cu121) (1.9.4)
Requirement already satisfied: async-timeout<5.0,>=4.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from aiohttp->datasets->auto_gptq==0.8.0.dev0+cu121) (4.0.3)
Requirement already satisfied: charset-normalizer<4,>=2 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto_gptq==0.8.0.dev0+cu121) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto_gptq==0.8.0.dev0+cu121) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto_gptq==0.8.0.dev0+cu121) (2.2.1)
Requirement already satisfied: certifi>=2017.4.17 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto_gptq==0.8.0.dev0+cu121) (2024.2.2)
Requirement already satisfied: MarkupSafe>=2.0 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (2.1.5)
Requirement already satisfied: python-dateutil>=2.8.2 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from pandas->datasets->auto_gptq==0.8.0.dev0+cu121) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from pandas->datasets->auto_gptq==0.8.0.dev0+cu121) (2024.1)
Requirement already satisfied: tzdata>=2022.7 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from pandas->datasets->auto_gptq==0.8.0.dev0+cu121) (2024.1)
Requirement already satisfied: mpmath>=0.19 in /lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages (from sympy->torch>=1.13.0->auto_gptq==0.8.0.dev0+cu121) (1.3.0)
Installing collected packages: auto_gptq
  Attempting uninstall: auto_gptq
    Found existing installation: auto_gptq 0.8.0.dev0+cu121
    Uninstalling auto_gptq-0.8.0.dev0+cu121:
      Successfully uninstalled auto_gptq-0.8.0.dev0+cu121
  Running setup.py develop for auto_gptq
Successfully installed auto_gptq-0.8.0.dev0+cu121
/lustre1/tier2/users/karnakar.reddy/miniconda3/envs/mix_depths/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Token indices sequence length is longer than the specified maximum sequence length for this model (2428601 > 1024). Running this sequence through the model will result in indexing errors
WARNING - If you have not already done so, please inject the following code at the very top of your 
quantization script so the packing stage is optimized for speed. Using too many cores may reduce packing performance.
----
import os
import math
max_threads = str(min(8, os.cpu_count()))
os.environ['OMP_NUM_THREADS'] = max_threads
os.environ['OPENBLAS_NUM_THREADS'] = max_threads
os.environ['MKL_NUM_THREADS'] = max_threads
os.environ['VECLIB_MAXIMUM_THREADS'] = max_threads
os.environ['NUMEXPR_NUM_THREADS'] = max_threads
os.environ['NUMEXPR_MAX_THREADS'] = max_threads
----

INFO - Start quantizing layer 1/48
INFO - Quantizing attn.c_attn in layer 1/48...
2024-05-21 09:03:22 INFO [auto_gptq.quantization.gptq] duration: 4.773139953613281
2024-05-21 09:03:22 INFO [auto_gptq.quantization.gptq] avg loss: 2.3663811683654785
INFO - Quantizing attn.c_proj in layer 1/48...
2024-05-21 09:03:23 INFO [auto_gptq.quantization.gptq] duration: 0.4540431499481201
2024-05-21 09:03:23 INFO [auto_gptq.quantization.gptq] avg loss: 0.003215983510017395
INFO - Quantizing mlp.c_fc in layer 1/48...
2024-05-21 09:03:24 INFO [auto_gptq.quantization.gptq] duration: 0.45824742317199707
2024-05-21 09:03:24 INFO [auto_gptq.quantization.gptq] avg loss: 18.65728759765625
INFO - Quantizing mlp.c_proj in layer 1/48...
2024-05-21 09:03:26 INFO [auto_gptq.quantization.gptq] duration: 1.9733765125274658
2024-05-21 09:03:26 INFO [auto_gptq.quantization.gptq] avg loss: 2.0235533714294434
INFO - Start quantizing layer 2/48
INFO - Quantizing attn.c_attn in layer 2/48...
2024-05-21 09:03:27 INFO [auto_gptq.quantization.gptq] duration: 0.45622801780700684
2024-05-21 09:03:27 INFO [auto_gptq.quantization.gptq] avg loss: 8.737899780273438
INFO - Quantizing attn.c_proj in layer 2/48...
2024-05-21 09:03:28 INFO [auto_gptq.quantization.gptq] duration: 0.4495818614959717
2024-05-21 09:03:28 INFO [auto_gptq.quantization.gptq] avg loss: 0.18510980904102325
INFO - Quantizing mlp.c_fc in layer 2/48...
2024-05-21 09:03:29 INFO [auto_gptq.quantization.gptq] duration: 0.4657745361328125
2024-05-21 09:03:29 INFO [auto_gptq.quantization.gptq] avg loss: 17.799089431762695
INFO - Quantizing mlp.c_proj in layer 2/48...
2024-05-21 09:03:31 INFO [auto_gptq.quantization.gptq] duration: 1.900153398513794
2024-05-21 09:03:31 INFO [auto_gptq.quantization.gptq] avg loss: 2.4027180671691895
INFO - Start quantizing layer 3/48
INFO - Quantizing attn.c_attn in layer 3/48...
2024-05-21 09:03:32 INFO [auto_gptq.quantization.gptq] duration: 0.456662654876709
2024-05-21 09:03:32 INFO [auto_gptq.quantization.gptq] avg loss: 11.54734992980957
INFO - Quantizing attn.c_proj in layer 3/48...
2024-05-21 09:03:33 INFO [auto_gptq.quantization.gptq] duration: 0.45041799545288086
2024-05-21 09:03:33 INFO [auto_gptq.quantization.gptq] avg loss: 0.2577279210090637
INFO - Quantizing mlp.c_fc in layer 3/48...
2024-05-21 09:03:33 INFO [auto_gptq.quantization.gptq] duration: 0.4630160331726074
2024-05-21 09:03:33 INFO [auto_gptq.quantization.gptq] avg loss: 24.233016967773438
INFO - Quantizing mlp.c_proj in layer 3/48...
2024-05-21 09:03:36 INFO [auto_gptq.quantization.gptq] duration: 1.8876323699951172
2024-05-21 09:03:36 INFO [auto_gptq.quantization.gptq] avg loss: 1.9569692611694336
INFO - Start quantizing layer 4/48
INFO - Quantizing attn.c_attn in layer 4/48...
2024-05-21 09:03:37 INFO [auto_gptq.quantization.gptq] duration: 0.4591789245605469
2024-05-21 09:03:37 INFO [auto_gptq.quantization.gptq] avg loss: 15.22700309753418
INFO - Quantizing attn.c_proj in layer 4/48...
2024-05-21 09:03:37 INFO [auto_gptq.quantization.gptq] duration: 0.44911813735961914
2024-05-21 09:03:37 INFO [auto_gptq.quantization.gptq] avg loss: 0.2957478165626526
INFO - Quantizing mlp.c_fc in layer 4/48...
2024-05-21 09:03:38 INFO [auto_gptq.quantization.gptq] duration: 0.4672508239746094
2024-05-21 09:03:38 INFO [auto_gptq.quantization.gptq] avg loss: 29.259380340576172
INFO - Quantizing mlp.c_proj in layer 4/48...
2024-05-21 09:03:41 INFO [auto_gptq.quantization.gptq] duration: 1.890183925628662
2024-05-21 09:03:41 INFO [auto_gptq.quantization.gptq] avg loss: 2.0250484943389893
INFO - Start quantizing layer 5/48
INFO - Quantizing attn.c_attn in layer 5/48...
2024-05-21 09:03:42 INFO [auto_gptq.quantization.gptq] duration: 0.45631933212280273
2024-05-21 09:03:42 INFO [auto_gptq.quantization.gptq] avg loss: 19.50341033935547
INFO - Quantizing attn.c_proj in layer 5/48...
2024-05-21 09:03:42 INFO [auto_gptq.quantization.gptq] duration: 0.45011305809020996
2024-05-21 09:03:42 INFO [auto_gptq.quantization.gptq] avg loss: 0.465048223733902
INFO - Quantizing mlp.c_fc in layer 5/48...
2024-05-21 09:03:43 INFO [auto_gptq.quantization.gptq] duration: 0.46347975730895996
2024-05-21 09:03:43 INFO [auto_gptq.quantization.gptq] avg loss: 32.265506744384766
INFO - Quantizing mlp.c_proj in layer 5/48...
2024-05-21 09:03:46 INFO [auto_gptq.quantization.gptq] duration: 1.888258457183838
2024-05-21 09:03:46 INFO [auto_gptq.quantization.gptq] avg loss: 2.2182483673095703
INFO - Start quantizing layer 6/48
INFO - Quantizing attn.c_attn in layer 6/48...
2024-05-21 09:03:46 INFO [auto_gptq.quantization.gptq] duration: 0.4554729461669922
2024-05-21 09:03:46 INFO [auto_gptq.quantization.gptq] avg loss: 21.92880630493164
INFO - Quantizing attn.c_proj in layer 6/48...
2024-05-21 09:03:47 INFO [auto_gptq.quantization.gptq] duration: 0.45092320442199707
2024-05-21 09:03:47 INFO [auto_gptq.quantization.gptq] avg loss: 0.527874231338501
INFO - Quantizing mlp.c_fc in layer 6/48...
2024-05-21 09:03:48 INFO [auto_gptq.quantization.gptq] duration: 0.46268153190612793
2024-05-21 09:03:48 INFO [auto_gptq.quantization.gptq] avg loss: 34.426124572753906
INFO - Quantizing mlp.c_proj in layer 6/48...
2024-05-21 09:03:50 INFO [auto_gptq.quantization.gptq] duration: 1.8984136581420898
2024-05-21 09:03:50 INFO [auto_gptq.quantization.gptq] avg loss: 2.408972978591919
INFO - Start quantizing layer 7/48
INFO - Quantizing attn.c_attn in layer 7/48...
2024-05-21 09:03:51 INFO [auto_gptq.quantization.gptq] duration: 0.45806336402893066
2024-05-21 09:03:51 INFO [auto_gptq.quantization.gptq] avg loss: 23.461322784423828
INFO - Quantizing attn.c_proj in layer 7/48...
2024-05-21 09:03:52 INFO [auto_gptq.quantization.gptq] duration: 0.4510788917541504
2024-05-21 09:03:52 INFO [auto_gptq.quantization.gptq] avg loss: 0.595481276512146
INFO - Quantizing mlp.c_fc in layer 7/48...
2024-05-21 09:03:52 INFO [auto_gptq.quantization.gptq] duration: 0.46283912658691406
2024-05-21 09:03:52 INFO [auto_gptq.quantization.gptq] avg loss: 36.38545227050781
INFO - Quantizing mlp.c_proj in layer 7/48...
2024-05-21 09:03:55 INFO [auto_gptq.quantization.gptq] duration: 1.8902981281280518
2024-05-21 09:03:55 INFO [auto_gptq.quantization.gptq] avg loss: 2.6111443042755127
INFO - Start quantizing layer 8/48
INFO - Quantizing attn.c_attn in layer 8/48...
2024-05-21 09:03:56 INFO [auto_gptq.quantization.gptq] duration: 0.4567885398864746
2024-05-21 09:03:56 INFO [auto_gptq.quantization.gptq] avg loss: 24.64664077758789
INFO - Quantizing attn.c_proj in layer 8/48...
2024-05-21 09:03:57 INFO [auto_gptq.quantization.gptq] duration: 0.45132899284362793
2024-05-21 09:03:57 INFO [auto_gptq.quantization.gptq] avg loss: 0.6769042015075684
INFO - Quantizing mlp.c_fc in layer 8/48...
2024-05-21 09:03:57 INFO [auto_gptq.quantization.gptq] duration: 0.4629824161529541
2024-05-21 09:03:57 INFO [auto_gptq.quantization.gptq] avg loss: 38.976463317871094
INFO - Quantizing mlp.c_proj in layer 8/48...
2024-05-21 09:04:00 INFO [auto_gptq.quantization.gptq] duration: 1.8942053318023682
2024-05-21 09:04:00 INFO [auto_gptq.quantization.gptq] avg loss: 2.8636350631713867
INFO - Start quantizing layer 9/48
INFO - Quantizing attn.c_attn in layer 9/48...
2024-05-21 09:04:01 INFO [auto_gptq.quantization.gptq] duration: 0.45690274238586426
2024-05-21 09:04:01 INFO [auto_gptq.quantization.gptq] avg loss: 27.598255157470703
INFO - Quantizing attn.c_proj in layer 9/48...
2024-05-21 09:04:01 INFO [auto_gptq.quantization.gptq] duration: 0.4493095874786377
2024-05-21 09:04:01 INFO [auto_gptq.quantization.gptq] avg loss: 0.8284077644348145
INFO - Quantizing mlp.c_fc in layer 9/48...
2024-05-21 09:04:02 INFO [auto_gptq.quantization.gptq] duration: 0.46396780014038086
2024-05-21 09:04:02 INFO [auto_gptq.quantization.gptq] avg loss: 42.011985778808594
INFO - Quantizing mlp.c_proj in layer 9/48...
2024-05-21 09:04:05 INFO [auto_gptq.quantization.gptq] duration: 1.8929152488708496
2024-05-21 09:04:05 INFO [auto_gptq.quantization.gptq] avg loss: 3.2115750312805176
INFO - Start quantizing layer 10/48
INFO - Quantizing attn.c_attn in layer 10/48...
2024-05-21 09:04:06 INFO [auto_gptq.quantization.gptq] duration: 0.45755743980407715
2024-05-21 09:04:06 INFO [auto_gptq.quantization.gptq] avg loss: 28.70944595336914
INFO - Quantizing attn.c_proj in layer 10/48...
2024-05-21 09:04:06 INFO [auto_gptq.quantization.gptq] duration: 0.451171875
2024-05-21 09:04:06 INFO [auto_gptq.quantization.gptq] avg loss: 0.8225249648094177
INFO - Quantizing mlp.c_fc in layer 10/48...
2024-05-21 09:04:07 INFO [auto_gptq.quantization.gptq] duration: 0.46578335762023926
2024-05-21 09:04:07 INFO [auto_gptq.quantization.gptq] avg loss: 44.95673370361328
INFO - Quantizing mlp.c_proj in layer 10/48...
2024-05-21 09:04:09 INFO [auto_gptq.quantization.gptq] duration: 1.8887403011322021
2024-05-21 09:04:09 INFO [auto_gptq.quantization.gptq] avg loss: 3.450887441635132
INFO - Start quantizing layer 11/48
INFO - Quantizing attn.c_attn in layer 11/48...
2024-05-21 09:04:10 INFO [auto_gptq.quantization.gptq] duration: 0.4558372497558594
2024-05-21 09:04:10 INFO [auto_gptq.quantization.gptq] avg loss: 30.971111297607422
INFO - Quantizing attn.c_proj in layer 11/48...
2024-05-21 09:04:11 INFO [auto_gptq.quantization.gptq] duration: 0.4515218734741211
2024-05-21 09:04:11 INFO [auto_gptq.quantization.gptq] avg loss: 0.8832607865333557
INFO - Quantizing mlp.c_fc in layer 11/48...
2024-05-21 09:04:12 INFO [auto_gptq.quantization.gptq] duration: 0.4640309810638428
2024-05-21 09:04:12 INFO [auto_gptq.quantization.gptq] avg loss: 48.011749267578125
INFO - Quantizing mlp.c_proj in layer 11/48...
2024-05-21 09:04:14 INFO [auto_gptq.quantization.gptq] duration: 1.8844060897827148
2024-05-21 09:04:14 INFO [auto_gptq.quantization.gptq] avg loss: 3.7919254302978516
INFO - Start quantizing layer 12/48
INFO - Quantizing attn.c_attn in layer 12/48...
2024-05-21 09:04:15 INFO [auto_gptq.quantization.gptq] duration: 0.4576239585876465
2024-05-21 09:04:15 INFO [auto_gptq.quantization.gptq] avg loss: 30.973201751708984
INFO - Quantizing attn.c_proj in layer 12/48...
2024-05-21 09:04:16 INFO [auto_gptq.quantization.gptq] duration: 0.4518156051635742
2024-05-21 09:04:16 INFO [auto_gptq.quantization.gptq] avg loss: 1.0563737154006958
INFO - Quantizing mlp.c_fc in layer 12/48...
2024-05-21 09:04:16 INFO [auto_gptq.quantization.gptq] duration: 0.4639017581939697
2024-05-21 09:04:16 INFO [auto_gptq.quantization.gptq] avg loss: 50.34812927246094
INFO - Quantizing mlp.c_proj in layer 12/48...
2024-05-21 09:04:19 INFO [auto_gptq.quantization.gptq] duration: 1.8905391693115234
2024-05-21 09:04:19 INFO [auto_gptq.quantization.gptq] avg loss: 3.895524740219116
INFO - Start quantizing layer 13/48
INFO - Quantizing attn.c_attn in layer 13/48...
2024-05-21 09:04:20 INFO [auto_gptq.quantization.gptq] duration: 0.4574394226074219
2024-05-21 09:04:20 INFO [auto_gptq.quantization.gptq] avg loss: 35.238067626953125
INFO - Quantizing attn.c_proj in layer 13/48...
2024-05-21 09:04:21 INFO [auto_gptq.quantization.gptq] duration: 0.44942808151245117
2024-05-21 09:04:21 INFO [auto_gptq.quantization.gptq] avg loss: 1.3269468545913696
INFO - Quantizing mlp.c_fc in layer 13/48...
2024-05-21 09:04:21 INFO [auto_gptq.quantization.gptq] duration: 0.4612550735473633
2024-05-21 09:04:21 INFO [auto_gptq.quantization.gptq] avg loss: 53.13966369628906
INFO - Quantizing mlp.c_proj in layer 13/48...
2024-05-21 09:04:24 INFO [auto_gptq.quantization.gptq] duration: 1.8917126655578613
2024-05-21 09:04:24 INFO [auto_gptq.quantization.gptq] avg loss: 4.188106536865234
INFO - Start quantizing layer 14/48
INFO - Quantizing attn.c_attn in layer 14/48...
2024-05-21 09:04:25 INFO [auto_gptq.quantization.gptq] duration: 0.45665812492370605
2024-05-21 09:04:25 INFO [auto_gptq.quantization.gptq] avg loss: 36.91542434692383
INFO - Quantizing attn.c_proj in layer 14/48...
2024-05-21 09:04:25 INFO [auto_gptq.quantization.gptq] duration: 0.45155882835388184
2024-05-21 09:04:25 INFO [auto_gptq.quantization.gptq] avg loss: 1.3227827548980713
INFO - Quantizing mlp.c_fc in layer 14/48...
2024-05-21 09:04:26 INFO [auto_gptq.quantization.gptq] duration: 0.4649968147277832
2024-05-21 09:04:26 INFO [auto_gptq.quantization.gptq] avg loss: 54.06003952026367
INFO - Quantizing mlp.c_proj in layer 14/48...
2024-05-21 09:04:29 INFO [auto_gptq.quantization.gptq] duration: 1.8842198848724365
2024-05-21 09:04:29 INFO [auto_gptq.quantization.gptq] avg loss: 4.450638771057129
INFO - Start quantizing layer 15/48
INFO - Quantizing attn.c_attn in layer 15/48...
2024-05-21 09:04:29 INFO [auto_gptq.quantization.gptq] duration: 0.45705485343933105
2024-05-21 09:04:29 INFO [auto_gptq.quantization.gptq] avg loss: 36.21385192871094
INFO - Quantizing attn.c_proj in layer 15/48...
2024-05-21 09:04:30 INFO [auto_gptq.quantization.gptq] duration: 0.44974184036254883
2024-05-21 09:04:30 INFO [auto_gptq.quantization.gptq] avg loss: 1.9699524641036987
INFO - Quantizing mlp.c_fc in layer 15/48...
2024-05-21 09:04:31 INFO [auto_gptq.quantization.gptq] duration: 0.46379923820495605
2024-05-21 09:04:31 INFO [auto_gptq.quantization.gptq] avg loss: 54.21742248535156
INFO - Quantizing mlp.c_proj in layer 15/48...
2024-05-21 09:04:33 INFO [auto_gptq.quantization.gptq] duration: 1.8873107433319092
2024-05-21 09:04:33 INFO [auto_gptq.quantization.gptq] avg loss: 5.0612335205078125
INFO - Start quantizing layer 16/48
INFO - Quantizing attn.c_attn in layer 16/48...
2024-05-21 09:04:34 INFO [auto_gptq.quantization.gptq] duration: 0.45580291748046875
2024-05-21 09:04:34 INFO [auto_gptq.quantization.gptq] avg loss: 38.804908752441406
INFO - Quantizing attn.c_proj in layer 16/48...
2024-05-21 09:04:35 INFO [auto_gptq.quantization.gptq] duration: 0.4521782398223877
2024-05-21 09:04:35 INFO [auto_gptq.quantization.gptq] avg loss: 1.8855926990509033
INFO - Quantizing mlp.c_fc in layer 16/48...
2024-05-21 09:04:35 INFO [auto_gptq.quantization.gptq] duration: 0.46248626708984375
2024-05-21 09:04:35 INFO [auto_gptq.quantization.gptq] avg loss: 55.464622497558594
INFO - Quantizing mlp.c_proj in layer 16/48...
2024-05-21 09:04:38 INFO [auto_gptq.quantization.gptq] duration: 1.8885753154754639
2024-05-21 09:04:38 INFO [auto_gptq.quantization.gptq] avg loss: 5.356967926025391
INFO - Start quantizing layer 17/48
INFO - Quantizing attn.c_attn in layer 17/48...
2024-05-21 09:04:39 INFO [auto_gptq.quantization.gptq] duration: 0.45792055130004883
2024-05-21 09:04:39 INFO [auto_gptq.quantization.gptq] avg loss: 42.0922966003418
INFO - Quantizing attn.c_proj in layer 17/48...
2024-05-21 09:04:40 INFO [auto_gptq.quantization.gptq] duration: 0.45041894912719727
2024-05-21 09:04:40 INFO [auto_gptq.quantization.gptq] avg loss: 2.1650078296661377
INFO - Quantizing mlp.c_fc in layer 17/48...
2024-05-21 09:04:40 INFO [auto_gptq.quantization.gptq] duration: 0.46279239654541016
2024-05-21 09:04:40 INFO [auto_gptq.quantization.gptq] avg loss: 57.5361213684082
INFO - Quantizing mlp.c_proj in layer 17/48...
2024-05-21 09:04:43 INFO [auto_gptq.quantization.gptq] duration: 1.9005076885223389
2024-05-21 09:04:43 INFO [auto_gptq.quantization.gptq] avg loss: 5.7342681884765625
INFO - Start quantizing layer 18/48
INFO - Quantizing attn.c_attn in layer 18/48...
2024-05-21 09:04:44 INFO [auto_gptq.quantization.gptq] duration: 0.4562547206878662
2024-05-21 09:04:44 INFO [auto_gptq.quantization.gptq] avg loss: 45.63152313232422
INFO - Quantizing attn.c_proj in layer 18/48...
2024-05-21 09:04:44 INFO [auto_gptq.quantization.gptq] duration: 0.45222949981689453
2024-05-21 09:04:44 INFO [auto_gptq.quantization.gptq] avg loss: 2.398782730102539
INFO - Quantizing mlp.c_fc in layer 18/48...
2024-05-21 09:04:45 INFO [auto_gptq.quantization.gptq] duration: 0.46425461769104004
2024-05-21 09:04:45 INFO [auto_gptq.quantization.gptq] avg loss: 58.69743347167969
INFO - Quantizing mlp.c_proj in layer 18/48...
2024-05-21 09:04:48 INFO [auto_gptq.quantization.gptq] duration: 1.8881278038024902
2024-05-21 09:04:48 INFO [auto_gptq.quantization.gptq] avg loss: 6.578080177307129
